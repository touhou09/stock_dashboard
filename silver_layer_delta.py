"""
Silver Layer - Delta Lake ê¸°ë°˜ ë°ì´í„° ì •ì œ ë° í†µí•©
Bronze Layerì—ì„œ ìˆ˜ì§‘í•œ Delta Tableì„ ê¸°ë°˜ìœ¼ë¡œ ë°°ë‹¹ì£¼ í•„í„°ë§ ë° í†µí•© í…Œì´ë¸” ìƒì„±
"""

import pandas as pd
from datetime import datetime, timedelta, date
from typing import Optional, List, Tuple
import logging
from deltalake import DeltaTable, write_deltalake
import pyarrow as pa

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SilverLayerDelta:
    """Silver Layer Delta Lake ê¸°ë°˜ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, gcs_bucket: str, bronze_path: str = "stock_dashboard/bronze", silver_path: str = "stock_dashboard/silver"):
        """
        Silver Layer ì´ˆê¸°í™”
        
        Args:
            gcs_bucket: GCS ë²„í‚· ì´ë¦„
            bronze_path: Bronze Layer ê²½ë¡œ
            silver_path: Silver Layer ê²½ë¡œ
        """
        self.gcs_bucket = gcs_bucket
        self.bronze_path = bronze_path
        self.silver_path = silver_path
        
        # Delta Table ê²½ë¡œ ì„¤ì •
        self.bronze_price_path = f"gs://{gcs_bucket}/{bronze_path}/sp500_daily_prices"
        self.bronze_dividend_path = f"gs://{gcs_bucket}/{bronze_path}/sp500_dividend_info"
        self.silver_unified_path = f"gs://{gcs_bucket}/{silver_path}/unified_stock_data"
        self.silver_dividend_path = f"gs://{gcs_bucket}/{silver_path}/dividend_stocks"
    
    def load_bronze_data(self, target_date: Optional[date] = None) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """Bronze Layerì—ì„œ Delta Table ë°ì´í„° ë¡œë“œ"""
        logger.info(f" Bronze Layer Delta Table ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        try:
            # Delta Tableì—ì„œ ë°ì´í„° ë¡œë“œ
            price_delta = DeltaTable(self.bronze_price_path)
            dividend_delta = DeltaTable(self.bronze_dividend_path)
            
            # pandas DataFrameìœ¼ë¡œ ë³€í™˜
            price_df = price_delta.to_pandas()
            dividend_df = dividend_delta.to_pandas()
            
            # ë‚ ì§œ í•„í„°ë§
            if target_date:
                price_df = price_df[price_df['date'] == target_date]
            
            logger.info(f"âœ… ê°€ê²© ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(price_df)}í–‰")
            logger.info(f"âœ… ë°°ë‹¹ ì •ë³´ ë¡œë“œ ì™„ë£Œ: {len(dividend_df)}í–‰")
            
            return price_df, dividend_df
            
        except Exception as e:
            logger.error(f"âŒ Bronze Layer ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            # ìˆ˜ì •: ì¼ê´€ì„± ìˆëŠ” ì—ëŸ¬ ë©”ì‹œì§€ë¡œ ì˜ˆì™¸ ì¬ë°œìƒ
            raise Exception(f"Bronze Layer ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}") from e
    
    def create_unified_table(self, price_df: pd.DataFrame, dividend_df: pd.DataFrame) -> pd.DataFrame:
        """í†µí•© í…Œì´ë¸” ìƒì„±"""
        logger.info(f"\nï¸ Silver Layer í†µí•© í…Œì´ë¸” ìƒì„± ì¤‘...")
        
        # Delta Lakeì˜ ìŠ¤í‚¤ë§ˆ ì§„í™”ë¥¼ ê³ ë ¤í•œ ìœ ì—°í•œ ì»¬ëŸ¼ ì„ íƒ
        # í•„ìˆ˜ ì»¬ëŸ¼ë§Œ í™•ì¸í•˜ê³ , ë‚˜ë¨¸ì§€ëŠ” ì„ íƒì 
        required_columns = ['ticker', 'company_name', 'sector', 'has_dividend', 'dividend_yield']
        
        # í•„ìˆ˜ ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸
        missing_required = [col for col in required_columns if col not in dividend_df.columns]
        if missing_required:
            raise ValueError(f"í•„ìˆ˜ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_required}")
        
        # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ (Delta Lakeì˜ ìŠ¤í‚¤ë§ˆ ì§„í™” ì§€ì›)
        available_columns = [col for col in dividend_df.columns if col in required_columns or 
                            col in ['dividend_yield_percent', 'dividend_rate', 'ex_dividend_date', 
                                   'payment_date', 'dividend_frequency', 'market_cap', 'last_price']]
        
        # ê°€ê²© ë°ì´í„°ì™€ ë°°ë‹¹ ì •ë³´ ì¡°ì¸
        unified_df = price_df.merge(
            dividend_df[available_columns], 
            on='ticker', 
            how='left'
        )
        
        # ë°°ë‹¹ì£¼ ì—¬ë¶€ í”Œë˜ê·¸
        unified_df['is_dividend_stock'] = unified_df['has_dividend'].fillna(False)
        unified_df['processing_timestamp'] = datetime.now()
        
        # ë°ì´í„° í’ˆì§ˆ ê²€ì¦
        total_count = len(unified_df)
        dividend_count = unified_df['is_dividend_stock'].sum()
        
        logger.info(f"ğŸ“Š ë°ì´í„° í’ˆì§ˆ ê²€ì¦:")
        logger.info(f"  ì „ì²´ ë ˆì½”ë“œ ìˆ˜: {total_count}")
        logger.info(f"  ë°°ë‹¹ì£¼ ë ˆì½”ë“œ ìˆ˜: {dividend_count}")
        logger.info(f"  ë°°ë‹¹ì£¼ ë¹„ìœ¨: {(dividend_count / total_count * 100):.1f}%")
        
        # ê²°ì¸¡ê°’ í™•ì¸
        logger.info(f"  ê²°ì¸¡ê°’ í˜„í™©:")
        for col in unified_df.columns:
            null_count = unified_df[col].isnull().sum()
            if null_count > 0:
                logger.info(f"    {col}: {null_count}ê°œ ({(null_count/total_count*100):.1f}%)")
        
        return unified_df
    
    def save_unified_data(self, unified_df: pd.DataFrame, target_date: Optional[date] = None):
        """í†µí•© ë°ì´í„°ë¥¼ Delta Tableì— ì €ì¥"""
        logger.info(f"\nğŸ’¾ Silver Layer í†µí•© ë°ì´í„° ì €ì¥ ì¤‘...")
        
        try:
            # ê¸°ì¡´ Delta Table í™•ì¸
            unified_delta = DeltaTable(self.silver_unified_path)
            mode = "append"
            logger.info("âœ… ê¸°ì¡´ í†µí•© Delta Tableì— ë°ì´í„° ì¶”ê°€")
        except Exception:
            mode = "overwrite"
            logger.info("ğŸ†• ìƒˆë¡œìš´ í†µí•© Delta Table ìƒì„±")
        
        # Delta Tableì— ì €ì¥
        write_deltalake(
            self.silver_unified_path,
            unified_df,
            mode=mode,
            partition_by=["date", "is_dividend_stock"],  # ë‚ ì§œì™€ ë°°ë‹¹ì£¼ ì—¬ë¶€ë³„ íŒŒí‹°ì…”ë‹
            engine="pyarrow"
        )
        
        logger.info(f"âœ… í†µí•© í…Œì´ë¸” ì €ì¥ ì™„ë£Œ: {len(unified_df)}í–‰")
        logger.info(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {self.silver_unified_path}")
        
        # ë°°ë‹¹ì£¼ë§Œ í•„í„°ë§í•œ í…Œì´ë¸” ì €ì¥
        dividend_stocks_df = unified_df[unified_df['is_dividend_stock'] == True]
        
        if not dividend_stocks_df.empty:
            try:
                dividend_delta = DeltaTable(self.silver_dividend_path)
                mode = "append"
                logger.info("âœ… ê¸°ì¡´ ë°°ë‹¹ì£¼ Delta Tableì— ë°ì´í„° ì¶”ê°€")
            except Exception:
                mode = "overwrite"
                logger.info("ğŸ†• ìƒˆë¡œìš´ ë°°ë‹¹ì£¼ Delta Table ìƒì„±")
            
            # Delta Tableì— ì €ì¥
            write_deltalake(
                self.silver_dividend_path,
                dividend_stocks_df,
                mode=mode,
                partition_by=["date", "sector"],  # ë‚ ì§œì™€ ì„¹í„°ë³„ íŒŒí‹°ì…”ë‹
                engine="pyarrow"
            )
            
            logger.info(f"âœ… ë°°ë‹¹ì£¼ í…Œì´ë¸” ì €ì¥ ì™„ë£Œ: {len(dividend_stocks_df)}í–‰")
            logger.info(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {self.silver_dividend_path}")
        else:
            logger.warning("ë°°ë‹¹ì£¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    def analyze_dividend_stocks(self, unified_df: pd.DataFrame):
        """ë°°ë‹¹ì£¼ ë¶„ì„ (pandas ê¸°ë°˜)"""
        logger.info(f"\nğŸ“ˆ ë°°ë‹¹ì£¼ ë¶„ì„ ê²°ê³¼:")
        
        dividend_stocks = unified_df[unified_df['is_dividend_stock'] == True]
        
        if dividend_stocks.empty:
            logger.info("ë°°ë‹¹ì£¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ì„¹í„°ë³„ ë°°ë‹¹ì£¼ ë¶„í¬
        sector_dist = dividend_stocks.groupby('sector').size().sort_values(ascending=False)
        logger.info(f"\n ì„¹í„°ë³„ ë°°ë‹¹ì£¼ ë¶„í¬:")
        for sector, count in sector_dist.head(10).items():
            logger.info(f"  {sector}: {count}ê°œ")
        
        # ë°°ë‹¹ìˆ˜ìµë¥  ìƒìœ„ 10ê°œ
        top_dividend = dividend_stocks.nlargest(10, 'dividend_yield_percent')[
            ['ticker', 'company_name', 'dividend_yield_percent', 'sector']
        ]
        logger.info(f"\nğŸ’° ë°°ë‹¹ìˆ˜ìµë¥  ìƒìœ„ 10ê°œ:")
        for _, row in top_dividend.iterrows():
            logger.info(f"  {row['ticker']} ({row['company_name'][:30]}): {row['dividend_yield_percent']:.2f}% - {row['sector']}")
        
        # ë°°ë‹¹ìˆ˜ìµë¥  í†µê³„
        logger.info(f"\nğŸ“Š ë°°ë‹¹ìˆ˜ìµë¥  í†µê³„:")
        logger.info(f"  í‰ê· : {dividend_stocks['dividend_yield_percent'].mean():.2f}%")
        logger.info(f"  ì¤‘ê°„ê°’: {dividend_stocks['dividend_yield_percent'].median():.2f}%")
        logger.info(f"  ìµœëŒ€ê°’: {dividend_stocks['dividend_yield_percent'].max():.2f}%")
        logger.info(f"  ìµœì†Œê°’: {dividend_stocks['dividend_yield_percent'].min():.2f}%")
    
    def run_silver_processing(self, target_date: Optional[date] = None):
        """Silver Layer ì „ì²´ ì²˜ë¦¬ ì‹¤í–‰"""
        if target_date is None:
            target_date = date.today()
        
        logger.info("=" * 80)
        logger.info(f" Silver Layer ì²˜ë¦¬ ì‹œì‘")
        logger.info("=" * 80)
        logger.info(f" ì²˜ë¦¬ ë‚ ì§œ: {target_date}")
        
        try:
            # 1. Bronze Layer ë°ì´í„° ë¡œë“œ
            logger.info(f"\n1ï¸âƒ£ Bronze Layer ë°ì´í„° ë¡œë“œ...")
            price_df, dividend_df = self.load_bronze_data(target_date)
            
            # 2. í†µí•© í…Œì´ë¸” ìƒì„±
            logger.info(f"\n2ï¸âƒ£ í†µí•© í…Œì´ë¸” ìƒì„±...")
            unified_df = self.create_unified_table(price_df, dividend_df)
            
            # 3. ë°ì´í„° ì €ì¥
            logger.info(f"\n3ï¸âƒ£ ë°ì´í„° ì €ì¥...")
            self.save_unified_data(unified_df, target_date)
            
            # 4. ë°°ë‹¹ì£¼ ë¶„ì„
            logger.info(f"\n4ï¸âƒ£ ë°°ë‹¹ì£¼ ë¶„ì„...")
            self.analyze_dividend_stocks(unified_df)
            
            # 5. ìµœì¢… ìš”ì•½
            logger.info("\n" + "=" * 80)
            logger.info("ğŸ“ˆ Silver Layer ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½")
            logger.info("=" * 80)
            logger.info(f" ì²˜ë¦¬ ë‚ ì§œ: {target_date}")
            logger.info(f"ğŸ“Š ì „ì²´ ì¢…ëª© ìˆ˜: {unified_df['ticker'].nunique()}ê°œ")
            logger.info(f"ğŸ’° ë°°ë‹¹ì£¼ ì¢…ëª© ìˆ˜: {unified_df['is_dividend_stock'].sum()}ê°œ")
            logger.info(f" ì €ì¥ëœ Delta Table:")
            logger.info(f"  - {self.silver_unified_path} (í†µí•© í…Œì´ë¸”)")
            logger.info(f"  - {self.silver_dividend_path} (ë°°ë‹¹ì£¼ í…Œì´ë¸”)")
            logger.info("=" * 80)
            
        except Exception as e:
            logger.error(f"âŒ Silver Layer ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            # ìˆ˜ì •: ì¼ê´€ì„± ìˆëŠ” ì—ëŸ¬ ë©”ì‹œì§€ë¡œ ì˜ˆì™¸ ì¬ë°œìƒ
            raise Exception(f"Silver Layer ì²˜ë¦¬ ì‹¤íŒ¨: {e}") from e

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import os
    
    # GCS ì„¤ì • (í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
    gcs_bucket = os.getenv("GCS_BUCKET", "your-stock-dashboard-bucket")
    
    silver_layer = SilverLayerDelta(gcs_bucket=gcs_bucket)
    
    try:
        silver_layer.run_silver_processing()
    except Exception as e:
        logger.error(f"âŒ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        raise

if __name__ == "__main__":
    main()

    
    try:
        silver_layer.run_silver_processing()
    except Exception as e:
        logger.error(f"âŒ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        raise

if __name__ == "__main__":
    main()
