"""
Silver Layer - Delta Lake ê¸°ë°˜ ê³„ì‚°/ì§‘ê³„ ì§€í‘œ ìƒì„±
Bronze Layerì˜ ì›ì²œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë°°ë‹¹ ì§€í‘œë¥¼ ê³„ì‚°í•˜ì—¬ ì €ì¥
- TTM ë°°ë‹¹ìˆ˜ìµë¥ , ë°°ë‹¹íšŸìˆ˜, ìµœê·¼ ë°°ë‹¹ì¼ ë“± ê³„ì‚°ëœ ì§€í‘œ
"""

import pandas as pd
from datetime import datetime, timedelta, date, timezone
from typing import Optional, List
import logging
from deltalake import DeltaTable, write_deltalake, WriterProperties
import pyarrow as pa
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ (ì„ íƒì )
try:
    load_dotenv()
except Exception:
    pass

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SilverLayerDelta:
    """Silver Layer Delta Lake ê¸°ë°˜ ê´€ë¦¬ í´ë˜ìŠ¤ - ê³„ì‚°ëœ ì§€í‘œë§Œ ì €ì¥"""
    
    def __init__(self, gcs_bucket: str, bronze_path: str = "stock_dashboard/bronze", silver_path: str = "stock_dashboard/silver"):
        """
        Silver Layer ì´ˆê¸°í™”
        
        Args:
            gcs_bucket: GCS ë²„í‚· ì´ë¦„
            bronze_path: Bronze Layer ê²½ë¡œ
            silver_path: Silver Layer ê²½ë¡œ
        """
        self.gcs_bucket = gcs_bucket
        self.bronze_path = bronze_path
        self.silver_path = silver_path
        
        # Bronze Layer Delta Table ê²½ë¡œ
        self.bronze_price_path = f"gs://{gcs_bucket}/{bronze_path}/bronze_price_daily"
        self.bronze_dividend_events_path = f"gs://{gcs_bucket}/{bronze_path}/bronze_dividend_events"
        
        # Silver Layer Delta Table ê²½ë¡œ
        self.silver_dividend_metrics_path = f"gs://{gcs_bucket}/{silver_path}/silver_dividend_metrics_daily"
    
    def load_bronze_price_data(self, target_date: date) -> pd.DataFrame:
        """Bronze Layerì—ì„œ ê°€ê²© ë°ì´í„° ë¡œë“œ"""
        logger.info(f" Bronze Layer ê°€ê²© ë°ì´í„° ë¡œë“œ ì¤‘... (ë‚ ì§œ: {target_date})")
        
        try:
            price_delta = DeltaTable(self.bronze_price_path)
            price_df = price_delta.to_pandas()
            
            # ë‚ ì§œ í•„í„°ë§
            if not price_df.empty and 'date' in price_df.columns:
                price_df['date'] = pd.to_datetime(price_df['date']).dt.date
                price_df = price_df[price_df['date'] == target_date]
                logger.info(f"âœ… ê°€ê²© ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(price_df)}í–‰")
                return price_df
            else:
                logger.warning("í•´ë‹¹ ë‚ ì§œì˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return pd.DataFrame(columns=['date', 'ticker', 'open', 'high', 'low', 'close', 'volume', 'adj_close', 'ingest_at'])
            
        except Exception as e:
            logger.error(f"âŒ Bronze ê°€ê²© ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise Exception(f"Bronze ê°€ê²© ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}") from e
    
    def load_bronze_dividend_events(self, target_date: date, lookback_days: int = 365) -> pd.DataFrame:
        """Bronze Layerì—ì„œ ë°°ë‹¹ ì´ë²¤íŠ¸ ë°ì´í„° ë¡œë“œ (TTM ê³„ì‚°ìš©)"""
        logger.info(f" Bronze Layer ë°°ë‹¹ ì´ë²¤íŠ¸ ë°ì´í„° ë¡œë“œ ì¤‘... (TTM: {lookback_days}ì¼)")
        
        try:
            # Delta Tableì—ì„œ ë°ì´í„° ë¡œë“œ
            dividend_delta = DeltaTable(self.bronze_dividend_events_path)
            dividend_df = dividend_delta.to_pandas()
            
            # TTM ê¸°ê°„ ê³„ì‚°
            start_date = target_date - timedelta(days=lookback_days)
            dividend_df['ex_date'] = pd.to_datetime(dividend_df['ex_date']).dt.date
            
            # TTM ê¸°ê°„ ë‚´ ë°°ë‹¹ ì´ë²¤íŠ¸ë§Œ í•„í„°ë§
            dividend_df = dividend_df[
                (dividend_df['ex_date'] >= start_date) & 
                (dividend_df['ex_date'] <= target_date)
            ]
            
            logger.info(f"âœ… ë°°ë‹¹ ì´ë²¤íŠ¸ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(dividend_df)}í–‰ (TTM ê¸°ê°„)")
            return dividend_df
            
        except Exception as e:
            logger.error(f"âŒ Bronze ë°°ë‹¹ ì´ë²¤íŠ¸ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise Exception(f"Bronze ë°°ë‹¹ ì´ë²¤íŠ¸ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}") from e
    
    def build_dividend_metrics_daily(self, price_df: pd.DataFrame, dividend_events_df: pd.DataFrame, target_date: date) -> pd.DataFrame:
        """
        ë°°ë‹¹ ì§€í‘œ ê³„ì‚° (Silver Layer í•µì‹¬ í•¨ìˆ˜)
        
        Args:
            price_df: Bronze ê°€ê²© ë°ì´í„°
            dividend_events_df: Bronze ë°°ë‹¹ ì´ë²¤íŠ¸ ë°ì´í„° (TTM ê¸°ê°„)
            target_date: ê³„ì‚° ê¸°ì¤€ì¼
            
        Returns:
            pd.DataFrame: ê³„ì‚°ëœ ë°°ë‹¹ ì§€í‘œ
        """
        logger.info(f"\nğŸ“Š ë°°ë‹¹ ì§€í‘œ ê³„ì‚° ì¤‘... (ê¸°ì¤€ì¼: {target_date})")
        
        # ê°€ê²© ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° ë¹ˆ DataFrame ë°˜í™˜
        if price_df.empty:
            logger.warning("ê°€ê²© ë°ì´í„°ê°€ ì—†ì–´ ë¹ˆ ë°°ë‹¹ ì§€í‘œ ë°˜í™˜")
            return pd.DataFrame(columns=['date', 'ticker', 'last_price', 'market_cap', 
                                       'dividend_ttm', 'dividend_yield_ttm', 'div_count_1y', 
                                       'last_div_date', 'updated_at'])
        
        metrics_list = []
        
        for _, price_row in price_df.iterrows():
            ticker = price_row['ticker']
            last_price = price_row['close']  # ê¸°ì¤€ì¼ ì¢…ê°€
            
            # í•´ë‹¹ í‹°ì»¤ì˜ TTM ë°°ë‹¹ ì´ë²¤íŠ¸ í•„í„°ë§
            ticker_dividends = dividend_events_df[
                dividend_events_df['ticker'] == ticker
            ].copy()
            
            if ticker_dividends.empty:
                # ë°°ë‹¹ ì´ë²¤íŠ¸ê°€ ì—†ëŠ” ê²½ìš°
                metrics = {
                    'date': target_date,
                    'ticker': ticker,
                    'last_price': last_price,
                    'market_cap': 0,  # Bronzeì— ì—†ìœ¼ë¯€ë¡œ 0ìœ¼ë¡œ ì„¤ì •
                    'dividend_ttm': 0.0,
                    'dividend_yield_ttm': 0.0,
                    'div_count_1y': 0,
                    'last_div_date': None,
                    'updated_at': datetime.now(timezone.utc)
                }
            else:
                # ë°°ë‹¹ ì§€í‘œ ê³„ì‚°
                dividend_ttm = ticker_dividends['amount'].sum()
                dividend_yield_ttm = (dividend_ttm / last_price) * 100 if last_price > 0 else 0.0
                div_count_1y = len(ticker_dividends)
                last_div_date = ticker_dividends['ex_date'].max()
                
                metrics = {
                    'date': target_date,
                    'ticker': ticker,
                    'last_price': last_price,
                    'market_cap': 0,  # Bronzeì— ì—†ìœ¼ë¯€ë¡œ 0ìœ¼ë¡œ ì„¤ì •
                    'dividend_ttm': dividend_ttm,
                    'dividend_yield_ttm': dividend_yield_ttm,
                    'div_count_1y': div_count_1y,
                    'last_div_date': last_div_date,
                    'updated_at': datetime.now(timezone.utc)
                }
            
            metrics_list.append(metrics)
        
        # DataFrameìœ¼ë¡œ ë³€í™˜
        metrics_df = pd.DataFrame(metrics_list)
        
        # ë°°ë‹¹ì£¼ í•„í„°ë§ (TTM ë°°ë‹¹ì´ ìˆëŠ” ì¢…ëª©)
        dividend_stocks = metrics_df[metrics_df['dividend_ttm'] > 0]
        
        logger.info(f" ê³„ì‚° ê²°ê³¼:")
        logger.info(f"  ì „ì²´ ì¢…ëª© ìˆ˜: {len(metrics_df)}ê°œ")
        logger.info(f"  ë°°ë‹¹ì£¼ ì¢…ëª© ìˆ˜: {len(dividend_stocks)}ê°œ")
        
        if not dividend_stocks.empty:
            logger.info(f"  TTM ë°°ë‹¹ìˆ˜ìµë¥  í‰ê· : {dividend_stocks['dividend_yield_ttm'].mean():.2f}%")
            logger.info(f"  TTM ë°°ë‹¹ìˆ˜ìµë¥  ìµœëŒ€: {dividend_stocks['dividend_yield_ttm'].max():.2f}%")
            
            # ë°°ë‹¹ìˆ˜ìµë¥  ìƒìœ„ 5ê°œ
            top_dividend = dividend_stocks.nlargest(5, 'dividend_yield_ttm')
            logger.info(f"  ë°°ë‹¹ìˆ˜ìµë¥  ìƒìœ„ 5ê°œ:")
            for _, row in top_dividend.iterrows():
                logger.info(f"    {row['ticker']}: {row['dividend_yield_ttm']:.2f}% (TTM: ${row['dividend_ttm']:.2f})")
        
        return metrics_df
    
    def save_dividend_metrics_to_delta(self, metrics_df: pd.DataFrame, target_date: date):
        """ë°°ë‹¹ ì§€í‘œë¥¼ Delta Tableì— ì €ì¥ (Silver ìŠ¤í‚¤ë§ˆ)"""
        logger.info(f"\nğŸ’¾ ë°°ë‹¹ ì§€í‘œë¥¼ Silver Delta Tableì— ì €ì¥ ì¤‘...")
        
        # ë¹ˆ DataFrameì¸ ê²½ìš° ì €ì¥ ê±´ë„ˆë›°ê¸°
        if metrics_df.empty:
            logger.warning("ë¹ˆ DataFrameì´ë¯€ë¡œ ì €ì¥ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return
        
        try:
            # Delta Tableì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            delta_table = DeltaTable(self.silver_dividend_metrics_path)
            
            # ê°™ì€ ë‚ ì§œì˜ ê¸°ì¡´ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
            existing_df = delta_table.to_pandas()
            if not existing_df.empty and 'date' in existing_df.columns:
                existing_df['date'] = pd.to_datetime(existing_df['date']).dt.date
                has_existing_data = (existing_df['date'] == target_date).any()
                
                if has_existing_data:
                    # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ í›„ ìƒˆ ë°ì´í„° ì¶”ê°€ (ë®ì–´ì“°ê¸°)
                    logger.info(f"ğŸ”„ {target_date} ë‚ ì§œì˜ ê¸°ì¡´ ë°ì´í„°ë¥¼ ì‚­ì œí•˜ê³  ìƒˆ ë°ì´í„°ë¡œ ë®ì–´ì“°ê¸°")
                    # ê¸°ì¡´ ë°ì´í„°ì—ì„œ í•´ë‹¹ ë‚ ì§œ ì œì™¸
                    existing_df = existing_df[existing_df['date'] != target_date]
                    # ê¸°ì¡´ ë°ì´í„°ì™€ ìƒˆ ë°ì´í„° ê²°í•©
                    if not existing_df.empty:
                        metrics_df = pd.concat([existing_df, metrics_df], ignore_index=True)
                    mode = "overwrite"
                else:
                    mode = "append"
                    logger.info("âœ… ê¸°ì¡´ Silver ë°°ë‹¹ ì§€í‘œ í…Œì´ë¸”ì— ë°ì´í„° ì¶”ê°€")
            else:
                mode = "append"
                logger.info("âœ… ê¸°ì¡´ Silver ë°°ë‹¹ ì§€í‘œ í…Œì´ë¸”ì— ë°ì´í„° ì¶”ê°€")
                
        except Exception:
            mode = "overwrite"
            logger.info("ğŸ†• ìƒˆë¡œìš´ Silver ë°°ë‹¹ ì§€í‘œ í…Œì´ë¸” ìƒì„±")
        
        # deltalake 1.0+ WriterPropertiesë¡œ zstd ì••ì¶• ì„¤ì •
        arrow_table = pa.Table.from_pandas(metrics_df)
        
        # zstd ì••ì¶• ì„¤ì •
        writer_props = WriterProperties(
            compression='ZSTD',
            compression_level=5
        )
        
        # Delta Tableì— ì €ì¥
        write_deltalake(
            self.silver_dividend_metrics_path,
            arrow_table,
            mode=mode,
            partition_by=["date"],  # ë‚ ì§œë³„ íŒŒí‹°ì…”ë‹
            writer_properties=writer_props,  # zstd ì••ì¶• ì ìš©
            configuration={
                "delta.dataSkippingStatsColumns": "ticker,dividend_yield_ttm",  # í†µê³„ ìµœì í™”
                "delta.autoOptimize.optimizeWrite": "true",                     # ìë™ ìµœì í™”
                "delta.autoOptimize.autoCompact": "true"                        # ìë™ ì••ì¶•
            }
        )
        
        logger.info(f"âœ… Silver ë°°ë‹¹ ì§€í‘œ ì €ì¥ ì™„ë£Œ: {len(metrics_df)}í–‰")
        logger.info(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {self.silver_dividend_metrics_path}")
    
    def analyze_dividend_metrics(self, metrics_df: pd.DataFrame):
        """ë°°ë‹¹ ì§€í‘œ ë¶„ì„"""
        logger.info(f"\nğŸ“ˆ ë°°ë‹¹ ì§€í‘œ ë¶„ì„ ê²°ê³¼:")
        
        dividend_stocks = metrics_df[metrics_df['dividend_ttm'] > 0]
        
        if dividend_stocks.empty:
            logger.info("ë°°ë‹¹ì£¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ë°°ë‹¹ìˆ˜ìµë¥  ë¶„í¬
        logger.info(f"\nğŸ“Š ë°°ë‹¹ìˆ˜ìµë¥  ë¶„í¬:")
        logger.info(f"  í‰ê· : {dividend_stocks['dividend_yield_ttm'].mean():.2f}%")
        logger.info(f"  ì¤‘ê°„ê°’: {dividend_stocks['dividend_yield_ttm'].median():.2f}%")
        logger.info(f"  ìµœëŒ€ê°’: {dividend_stocks['dividend_yield_ttm'].max():.2f}%")
        logger.info(f"  ìµœì†Œê°’: {dividend_stocks['dividend_yield_ttm'].min():.2f}%")
        
        # ë°°ë‹¹ìˆ˜ìµë¥  êµ¬ê°„ë³„ ë¶„í¬
        bins = [0, 1, 2, 3, 5, 10, float('inf')]
        labels = ['0-1%', '1-2%', '2-3%', '3-5%', '5-10%', '10%+']
        dividend_stocks_copy = dividend_stocks.copy()
        dividend_stocks_copy['yield_range'] = pd.cut(dividend_stocks_copy['dividend_yield_ttm'], bins=bins, labels=labels, right=False)
        
        logger.info(f"\nğŸ“Š ë°°ë‹¹ìˆ˜ìµë¥  êµ¬ê°„ë³„ ë¶„í¬:")
        yield_dist = dividend_stocks_copy['yield_range'].value_counts().sort_index()
        for range_label, count in yield_dist.items():
            logger.info(f"  {range_label}: {count}ê°œ")
        
        # ë°°ë‹¹ íšŸìˆ˜ ë¶„í¬
        logger.info(f"\nğŸ“Š ì—°ê°„ ë°°ë‹¹ íšŸìˆ˜ ë¶„í¬:")
        div_count_dist = dividend_stocks['div_count_1y'].value_counts().sort_index()
        for count, freq in div_count_dist.items():
            logger.info(f"  {count}íšŒ: {freq}ê°œ ì¢…ëª©")
        
        # ë°°ë‹¹ìˆ˜ìµë¥  ìƒìœ„ 10ê°œ
        top_dividend = dividend_stocks.nlargest(10, 'dividend_yield_ttm')
        logger.info(f"\nğŸ’° ë°°ë‹¹ìˆ˜ìµë¥  ìƒìœ„ 10ê°œ:")
        for i, (_, row) in enumerate(top_dividend.iterrows(), 1):
            last_div = row['last_div_date'].strftime('%Y-%m-%d') if pd.notna(row['last_div_date']) else 'N/A'
            logger.info(f"  {i:2d}. {row['ticker']}: {row['dividend_yield_ttm']:.2f}% "
                       f"(TTM: ${row['dividend_ttm']:.2f}, íšŸìˆ˜: {row['div_count_1y']}íšŒ, "
                       f"ìµœê·¼: {last_div})")
    
    def get_available_bronze_dates(self) -> List[date]:
        """Bronze Layerì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ë‚ ì§œ ì¡°íšŒ"""
        logger.info("ğŸ” Bronze Layer ì‚¬ìš© ê°€ëŠ¥í•œ ë‚ ì§œ ì¡°íšŒ ì¤‘...")
        
        try:
            price_delta = DeltaTable(self.bronze_price_path)
            price_df = price_delta.to_pandas()
            
            if not price_df.empty and 'date' in price_df.columns:
                price_df['date'] = pd.to_datetime(price_df['date']).dt.date
                unique_dates = sorted(price_df['date'].unique())
                logger.info(f"âœ… Bronze Layer ë‚ ì§œ ì¡°íšŒ ì™„ë£Œ: {len(unique_dates)}ê°œ ë‚ ì§œ")
                return unique_dates
            else:
                logger.warning("Bronze Layerì—ì„œ ë‚ ì§œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return []
                
        except Exception as e:
            logger.error(f"âŒ Bronze Layer ë‚ ì§œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def get_existing_silver_dates(self) -> List[date]:
        """Silver Layerì—ì„œ ì´ë¯¸ ì²˜ë¦¬ëœ ë‚ ì§œ ì¡°íšŒ"""
        logger.info("ğŸ” Silver Layer ê¸°ì¡´ ì²˜ë¦¬ ë‚ ì§œ ì¡°íšŒ ì¤‘...")
        
        try:
            silver_delta = DeltaTable(self.silver_dividend_metrics_path)
            silver_df = silver_delta.to_pandas()
            
            if not silver_df.empty and 'date' in silver_df.columns:
                silver_df['date'] = pd.to_datetime(silver_df['date']).dt.date
                unique_dates = sorted(silver_df['date'].unique())
                logger.info(f"âœ… Silver Layer ê¸°ì¡´ ë‚ ì§œ ì¡°íšŒ ì™„ë£Œ: {len(unique_dates)}ê°œ ë‚ ì§œ")
                return unique_dates
            else:
                logger.info("Silver Layerì— ê¸°ì¡´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return []
                
        except Exception as e:
            logger.info(f"Silver Layer ê¸°ì¡´ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨ (í…Œì´ë¸” ì—†ìŒ): {e}")
            return []
    
    def run_silver_backfill(self, start_date: Optional[date] = None, end_date: Optional[date] = None):
        """Silver Layer Backfill ì‹¤í–‰ - ì—¬ëŸ¬ ë‚ ì§œ ì¼ê´„ ì²˜ë¦¬"""
        logger.info("=" * 80)
        logger.info(" Silver Layer Backfill ì²˜ë¦¬ ì‹œì‘")
        logger.info("=" * 80)
        
        # 1. Bronze Layerì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ë‚ ì§œ ì¡°íšŒ
        logger.info(f"\n1ï¸âƒ£ Bronze Layer ì‚¬ìš© ê°€ëŠ¥í•œ ë‚ ì§œ ì¡°íšŒ...")
        available_dates = self.get_available_bronze_dates()
        
        if not available_dates:
            logger.error("âŒ Bronze Layerì— ì²˜ë¦¬í•  ë‚ ì§œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # 2. Silver Layerì—ì„œ ì´ë¯¸ ì²˜ë¦¬ëœ ë‚ ì§œ ì¡°íšŒ
        logger.info(f"\n2ï¸âƒ£ Silver Layer ê¸°ì¡´ ì²˜ë¦¬ ë‚ ì§œ ì¡°íšŒ...")
        existing_dates = self.get_existing_silver_dates()
        
        # 3. ì²˜ë¦¬í•  ë‚ ì§œ í•„í„°ë§
        if start_date:
            available_dates = [d for d in available_dates if d >= start_date]
        if end_date:
            available_dates = [d for d in available_dates if d <= end_date]
        
        # ê¸°ì¡´ì— ì²˜ë¦¬ë˜ì§€ ì•Šì€ ë‚ ì§œë§Œ ì„ íƒ
        dates_to_process = [d for d in available_dates if d not in existing_dates]
        
        logger.info(f"\nğŸ“Š Backfill ì²˜ë¦¬ ê³„íš:")
        logger.info(f"   Bronze Layer ì „ì²´ ë‚ ì§œ: {len(available_dates)}ê°œ")
        logger.info(f"   Silver Layer ê¸°ì¡´ ë‚ ì§œ: {len(existing_dates)}ê°œ")
        logger.info(f"   ì²˜ë¦¬í•  ë‚ ì§œ: {len(dates_to_process)}ê°œ")
        
        if not dates_to_process:
            logger.info("âœ… ëª¨ë“  ë‚ ì§œê°€ ì´ë¯¸ ì²˜ë¦¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            return
        
        # 4. ê° ë‚ ì§œë³„ë¡œ Silver Layer ì²˜ë¦¬
        successful_dates = []
        failed_dates = []
        
        for i, target_date in enumerate(dates_to_process, 1):
            logger.info(f"\n{'='*60}")
            logger.info(f"ğŸ“… ë‚ ì§œ {i}/{len(dates_to_process)} ì²˜ë¦¬ ì¤‘: {target_date}")
            logger.info(f"{'='*60}")
            
            try:
                # ê°œë³„ ë‚ ì§œ ì²˜ë¦¬
                self.run_silver_processing(target_date)
                successful_dates.append(target_date)
                logger.info(f"âœ… {target_date} ì²˜ë¦¬ ì™„ë£Œ")
                
            except Exception as e:
                failed_dates.append((target_date, str(e)))
                logger.error(f"âŒ {target_date} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                # ê°œë³„ ë‚ ì§œ ì‹¤íŒ¨ ì‹œì—ë„ ê³„ì† ì§„í–‰
                continue
        
        # 5. ìµœì¢… ìš”ì•½
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ“ˆ Silver Layer Backfill ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½")
        logger.info("=" * 80)
        logger.info(f" ì „ì²´ ì²˜ë¦¬ ë‚ ì§œ: {len(dates_to_process)}ê°œ")
        logger.info(f" ì„±ê³µí•œ ë‚ ì§œ: {len(successful_dates)}ê°œ")
        logger.info(f" ì‹¤íŒ¨í•œ ë‚ ì§œ: {len(failed_dates)}ê°œ")
        
        if successful_dates:
            logger.info(f"\nâœ… ì„±ê³µí•œ ë‚ ì§œ:")
            for date in successful_dates:
                logger.info(f"   - {date}")
        
        if failed_dates:
            logger.info(f"\nâŒ ì‹¤íŒ¨í•œ ë‚ ì§œ:")
            for date, error in failed_dates:
                logger.info(f"   - {date}: {error}")
        
        logger.info("=" * 80)
    
    def run_silver_processing(self, target_date: Optional[date] = None):
        """Silver Layer ì „ì²´ ì²˜ë¦¬ ì‹¤í–‰"""
        if target_date is None:
            target_date = datetime.now().date() - timedelta(days=1)
        
        logger.info("=" * 80)
        logger.info(" Silver Layer ì²˜ë¦¬ ì‹œì‘")
        logger.info("=" * 80)
        logger.info(f" ì²˜ë¦¬ ë‚ ì§œ: {target_date}")
        
        try:
            # 1. Bronze Layer ì›ì²œ ë°ì´í„° ë¡œë“œ
            logger.info(f"\n1ï¸âƒ£ Bronze Layer ì›ì²œ ë°ì´í„° ë¡œë“œ...")
            price_df = self.load_bronze_price_data(target_date)
            dividend_events_df = self.load_bronze_dividend_events(target_date, lookback_days=365)
            
            # 2. ë°°ë‹¹ ì§€í‘œ ê³„ì‚° (Silver Layer í•µì‹¬)
            logger.info(f"\n2ï¸âƒ£ ë°°ë‹¹ ì§€í‘œ ê³„ì‚° (Silver)...")
            metrics_df = self.build_dividend_metrics_daily(price_df, dividend_events_df, target_date)
            
            # 3. Silver Layer ì €ì¥
            logger.info(f"\n3ï¸âƒ£ Silver Layer ì €ì¥...")
            self.save_dividend_metrics_to_delta(metrics_df, target_date)
            
            # 4. ë°°ë‹¹ ì§€í‘œ ë¶„ì„
            logger.info(f"\n4ï¸âƒ£ ë°°ë‹¹ ì§€í‘œ ë¶„ì„...")
            self.analyze_dividend_metrics(metrics_df)
            
            # 5. ìµœì¢… ìš”ì•½
            logger.info("\n" + "=" * 80)
            logger.info("ğŸ“ˆ Silver Layer ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½")
            logger.info("=" * 80)
            logger.info(f" ì²˜ë¦¬ ë‚ ì§œ: {target_date}")
            logger.info(f"ğŸ“Š ì „ì²´ ì¢…ëª© ìˆ˜: {len(metrics_df)}ê°œ")
            logger.info(f"ğŸ“Š ë°°ë‹¹ì£¼ ì¢…ëª© ìˆ˜: {len(metrics_df[metrics_df['dividend_ttm'] > 0])}ê°œ")
            logger.info(f" ì €ì¥ëœ Silver Delta Table:")
            logger.info(f"  - {self.silver_dividend_metrics_path}")
            logger.info("=" * 80)
            
        except Exception as e:
            logger.error(f"âŒ Silver Layer ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise Exception(f"Silver Layer ì²˜ë¦¬ ì‹¤íŒ¨: {e}") from e

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import os
    
    # GCS ì„¤ì • (í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
    gcs_bucket = os.getenv("GCS_BUCKET", "your-stock-dashboard-bucket")
    
    silver_layer = SilverLayerDelta(gcs_bucket=gcs_bucket)
    
    try:
        silver_layer.run_silver_processing()
    except Exception as e:
        logger.error(f"âŒ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        raise

if __name__ == "__main__":
    main()
