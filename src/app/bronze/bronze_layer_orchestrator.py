"""
Bronze Layer ì¡°ìœ¨ì - ê°€ê²©/ë°°ë‹¹ ë°ì´í„° ìˆ˜ì§‘ì„ ì˜µì…˜ë³„ë¡œ ë¶„ë¦¬
"""

import os
from datetime import datetime, timedelta
from typing import Optional
import logging
import pandas as pd
from dotenv import load_dotenv

from src.utils.data_collectors import SP500Collector, PriceDataCollector, DividendDataCollector
from src.utils.data_storage import DeltaStorageManager
from src.utils.data_validators import DataValidator, BackfillValidator

try:
    load_dotenv()
except Exception:
    pass
logger = logging.getLogger(__name__)

class BronzeLayerOrchestrator:
    """Bronze Layer ì¡°ìœ¨ì - ì˜µì…˜ë³„ ë°ì´í„° ìˆ˜ì§‘ ê´€ë¦¬"""
    
    def __init__(self, gcs_bucket: str, gcs_path: str = "stock_dashboard/bronze"):
        self.storage_manager = DeltaStorageManager(gcs_bucket, gcs_path)
        self.sp500_collector = SP500Collector()
        self.price_collector = PriceDataCollector()
        self.dividend_collector = DividendDataCollector()
        self.data_validator = DataValidator()
        self.backfill_validator = BackfillValidator(self.storage_manager)
    
    def get_sp500_tickers(self, target_date: Optional[datetime.date] = None) -> list:
        """
        S&P 500 ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ìˆ˜ì§‘ (ìˆœìˆ˜ í˜„ì¬ ëª©ë¡ë§Œ ì‚¬ìš©)
        
        Args:
            target_date: ëŒ€ìƒ ë‚ ì§œ (ì‚¬ìš©í•˜ì§€ ì•ŠìŒ, í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€)
            
        Returns:
            list: í˜„ì¬ S&P 500 í‹°ì»¤ ë¦¬ìŠ¤íŠ¸
        """
        # [ìˆ˜ì •] ì„ íƒí¸í–¥ ë¡œì§ ì œê±° - í•­ìƒ í˜„ì¬ S&P 500 ëª©ë¡ë§Œ ì‚¬ìš©
        logger.info("ğŸ“‹ í˜„ì¬ S&P 500 ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ìˆ˜ì§‘ (ì„ íƒí¸í–¥ ì œê±°)...")
        spx_raw = self.sp500_collector.get_sp500_from_wikipedia()
        spx = self.sp500_collector.normalize_symbols(spx_raw)
        tickers = spx["Symbol"].dropna().unique().tolist()
        logger.info(f"âœ… í˜„ì¬ S&P 500 ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ìˆ˜ì§‘ ì™„ë£Œ: {len(tickers)}ê°œ")
        
        return tickers
    
    def run_price_only_collection(self, target_date: Optional[datetime.date] = None, batch_size: int = 50):
        """ê°€ê²© ë°ì´í„°ë§Œ ìˆ˜ì§‘ (ë°°ì¹˜ ë‹¨ìœ„ ì €ì¥)"""
        if target_date is None:
            target_date = datetime.now().date() - timedelta(days=1)
        
        logger.info("=" * 80)
        logger.info("ğŸ“Š Bronze Layer ê°€ê²© ë°ì´í„° ìˆ˜ì§‘")
        logger.info("=" * 80)
        logger.info(f" ìˆ˜ì§‘ ë‚ ì§œ: {target_date}")
        logger.info(f" ë°°ì¹˜ í¬ê¸°: {batch_size}ê°œì”© ì²˜ë¦¬")
        
        try:
            # [ìˆ˜ì •] 1. í•´ë‹¹ ë‚ ì§œ ë°ì´í„° ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            logger.info(f"ğŸ” {target_date} ë°ì´í„° ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ì¤‘...")
            has_existing_data = self.storage_manager.check_existing_data(
                self.storage_manager.price_table_path, target_date
            )
            
            if has_existing_data:
                logger.info(f"â­ï¸ {target_date} ê°€ê²© ë°ì´í„°ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤ - ê±´ë„ˆëœë‹ˆë‹¤")
                return True
            
            logger.info(f"ğŸ“Š {target_date} ê°€ê²© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤ - ìˆ˜ì§‘ ì‹œì‘")
            
            # 2. S&P 500 ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ìˆ˜ì§‘ (ë‚ ì§œë³„)
            tickers = self.get_sp500_tickers(target_date)
            total_tickers = len(tickers)
            
            # 2. ë°°ì¹˜ ë‹¨ìœ„ë¡œ ê°€ê²© ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥
            logger.info(f"\nğŸ“ˆ ê°€ê²© ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘... (ì´ {total_tickers}ê°œ â†’ {(total_tickers + batch_size - 1) // batch_size}ê°œ ë°°ì¹˜)")
            
            total_successful = 0
            total_failed = 0
            all_batch_data = []  # ëª¨ë“  ë°°ì¹˜ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•  ë¦¬ìŠ¤íŠ¸
            
            # [ìˆ˜ì •] ë°°ì¹˜ ë‹¨ìœ„ë¡œ ìˆ˜ì§‘ë§Œ ìˆ˜í–‰
            for batch_num in range(0, total_tickers, batch_size):
                batch_tickers = tickers[batch_num:batch_num + batch_size]
                batch_idx = batch_num // batch_size + 1
                total_batches = (total_tickers + batch_size - 1) // batch_size
                
                logger.info(f"\nğŸ”„ ë°°ì¹˜ {batch_idx}/{total_batches} ì²˜ë¦¬ ì¤‘... ({len(batch_tickers)}ê°œ ì¢…ëª©)")
                
                # ë°°ì¹˜ ë°ì´í„° ìˆ˜ì§‘
                batch_data, successful_tickers, failed_tickers = self.price_collector.get_daily_data_for_tickers(batch_tickers, target_date)
                
                if batch_data:
                    # ë°ì´í„° ê²€ì¦
                    for data in batch_data:
                        self.data_validator.validate_price_data(data)
                    
                    # ë°°ì¹˜ ë°ì´í„°ë¥¼ ì „ì²´ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                    all_batch_data.extend(batch_data)
                    logger.info(f"âœ… ë°°ì¹˜ {batch_idx} ìˆ˜ì§‘ ì™„ë£Œ: {len(successful_tickers)}ê°œ ì„±ê³µ, {len(failed_tickers)}ê°œ ì‹¤íŒ¨")
                
                total_successful += len(successful_tickers)
                total_failed += len(failed_tickers)
            
            # [ìˆ˜ì •] ëª¨ë“  ë°°ì¹˜ ìˆ˜ì§‘ ì™„ë£Œ í›„ í•œ ë²ˆì— ì €ì¥
            if all_batch_data:
                logger.info(f"\nğŸ’¾ ëª¨ë“  ë°°ì¹˜ ë°ì´í„° ì €ì¥ ì¤‘... (ì´ {len(all_batch_data)}ê°œ ë°ì´í„°)")
                self.storage_manager.save_price_data_to_delta(all_batch_data, target_date)
                logger.info(f"âœ… ì „ì²´ ë°ì´í„° ì €ì¥ ì™„ë£Œ")
            
            logger.info(f"\nâœ… ì „ì²´ ê°€ê²© ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: ì„±ê³µ {total_successful}ê°œ, ì‹¤íŒ¨ {total_failed}ê°œ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ê°€ê²© ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def get_latest_dividend_date(self) -> Optional[datetime.date]:
        """Delta Tableì—ì„œ ê°€ì¥ ìµœê·¼ ë°°ë‹¹ ì´ë²¤íŠ¸ ë‚ ì§œ ì¡°íšŒ"""
        try:
            from deltalake import DeltaTable
            table_path = self.storage_manager.dividend_events_table_path
            
            delta_table = DeltaTable(table_path)
            df = delta_table.to_pandas()
            
            if df.empty:
                return None
            
            # ex_date ì»¬ëŸ¼ì—ì„œ ìµœê·¼ ë‚ ì§œ ì°¾ê¸°
            df['ex_date'] = pd.to_datetime(df['ex_date']).dt.date
            latest_date = df['ex_date'].max()
            
            logger.info(f"ğŸ“… ê¸°ì¡´ ë°°ë‹¹ ë°ì´í„° ìµœê·¼ ë‚ ì§œ: {latest_date}")
            return latest_date
            
        except Exception as e:
            logger.info(f"ğŸ“… ê¸°ì¡´ ë°°ë‹¹ ë°ì´í„° ì—†ìŒ (í…Œì´ë¸” ì—†ê±°ë‚˜ ë¹„ì–´ìˆìŒ): {e}")
            return None
    
    def run_dividend_only_collection(self, target_date: Optional[datetime.date] = None):
        """ë°°ë‹¹ ë°ì´í„°ë§Œ ìˆ˜ì§‘ (ì¦ë¶„ ìˆ˜ì§‘)"""
        if target_date is None:
            target_date = datetime.now().date() - timedelta(days=1)
        
        logger.info("=" * 80)
        logger.info("ğŸ’° Bronze Layer ë°°ë‹¹ ë°ì´í„° ìˆ˜ì§‘ (ì¦ë¶„ ìˆ˜ì§‘)")
        logger.info("=" * 80)
        logger.info(f" ìˆ˜ì§‘ ë‚ ì§œ: {target_date}")
        
        try:
            # 1. S&P 500 ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ìˆ˜ì§‘ (ë‚ ì§œë³„)
            tickers = self.get_sp500_tickers(target_date)
            
            # 2. [ìˆ˜ì •] ê¸°ì¡´ ë°ì´í„° ìµœê·¼ ë‚ ì§œ í™•ì¸ (ì¦ë¶„ ìˆ˜ì§‘)
            latest_date = self.get_latest_dividend_date()
            
            if latest_date is not None:
                # ì¦ë¶„ ìˆ˜ì§‘: ìµœê·¼ ë‚ ì§œ ë‹¤ìŒë‚ ë¶€í„° ìˆ˜ì§‘
                since = latest_date + timedelta(days=1)
                logger.info(f"ğŸ”„ ì¦ë¶„ ìˆ˜ì§‘: {since} ~ {target_date}")
                
                if since > target_date:
                    logger.info(f"âœ… ì´ë¯¸ ìµœì‹  ë°ì´í„° ë³´ìœ  (ìµœê·¼: {latest_date})")
                    return True
            else:
                # ì´ˆê¸° ìˆ˜ì§‘: 400ì¼ì¹˜ ì „ì²´ ìˆ˜ì§‘
                since = target_date - timedelta(days=400)
                logger.info(f"ğŸ†• ì´ˆê¸° ìˆ˜ì§‘: {since} ~ {target_date} (400ì¼ì¹˜)")
            
            # 3. ë°°ë‹¹ ì´ë²¤íŠ¸ ìˆ˜ì§‘
            logger.info(f"\nğŸ’° ë°°ë‹¹ ì´ë²¤íŠ¸ ìˆ˜ì§‘ ì‹œì‘...")
            dividend_events_df = self.dividend_collector.fetch_dividend_events_for_tickers(tickers, since, target_date, target_date)
            
            if not dividend_events_df.empty:
                # ë°ì´í„° ê²€ì¦
                self.data_validator.validate_dividend_data(dividend_events_df)
                self.storage_manager.save_dividend_events_to_delta(dividend_events_df)
                logger.info(f"âœ… ë°°ë‹¹ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(dividend_events_df)}ê°œ ì´ë²¤íŠ¸")
            else:
                logger.info(f"âœ… ë°°ë‹¹ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: 0ê°œ ì´ë²¤íŠ¸ (ê¸°ê°„: {since} ~ {target_date})")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ ë°°ë‹¹ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def run_full_collection(self, target_date: Optional[datetime.date] = None, batch_size: int = 50):
        """ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ (ê°€ê²© + ë°°ë‹¹)"""
        if target_date is None:
            target_date = datetime.now().date() - timedelta(days=1)
        
        logger.info("=" * 80)
        logger.info("ğŸ“Š Bronze Layer ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ (ê°€ê²© + ë°°ë‹¹)")
        logger.info("=" * 80)
        logger.info(f" ìˆ˜ì§‘ ë‚ ì§œ: {target_date}")
        logger.info(f" ë°°ì¹˜ í¬ê¸°: {batch_size}ê°œì”© ì²˜ë¦¬")
        
        # ê°€ê²© ë°ì´í„° ìˆ˜ì§‘ (ë°°ì¹˜ ë‹¨ìœ„)
        price_success = self.run_price_only_collection(target_date, batch_size=batch_size)
        
        # ë°°ë‹¹ ë°ì´í„° ìˆ˜ì§‘
        dividend_success = self.run_dividend_only_collection(target_date)
        
        # ìµœì¢… ê²°ê³¼
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ“ˆ Bronze Layer ì „ì²´ ìˆ˜ì§‘ ê²°ê³¼")
        logger.info("=" * 80)
        logger.info(f" ìˆ˜ì§‘ ë‚ ì§œ: {target_date}")
        logger.info(f"âœ… ê°€ê²© ë°ì´í„°: {'ì„±ê³µ' if price_success else 'ì‹¤íŒ¨'}")
        logger.info(f"âœ… ë°°ë‹¹ ë°ì´í„°: {'ì„±ê³µ' if dividend_success else 'ì‹¤íŒ¨'}")
        logger.info("=" * 80)
        
        return price_success and dividend_success
    
    def run_bronze_backfill(self, start_date: datetime.date, end_date: datetime.date, batch_size: int = 50) -> bool:
        """
        Bronze Layer ë°±í•„ ì‹¤í–‰ - ì—¬ëŸ¬ ë‚ ì§œ ì¼ê´„ ì²˜ë¦¬
        
        Args:
            start_date: ì‹œì‘ ë‚ ì§œ
            end_date: ì¢…ë£Œ ë‚ ì§œ
            batch_size: ë°°ì¹˜ í¬ê¸°
            
        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        """
        logger.info("=" * 80)
        logger.info("ğŸ¥‰ Bronze Layer ë°±í•„ ì‹œì‘")
        logger.info("=" * 80)
        logger.info(f" ë°±í•„ ê¸°ê°„: {start_date} ~ {end_date}")
        logger.info(f" ë°°ì¹˜ í¬ê¸°: {batch_size}ê°œì”© ì²˜ë¦¬")
        
        try:
            # ë‚ ì§œ ë¦¬ìŠ¤íŠ¸ ìƒì„± (í‰ì¼ë§Œ)
            date_list = []
            current_date = start_date
            while current_date <= end_date:
                if current_date.weekday() < 5:  # 0-4: ì›”-ê¸ˆ
                    date_list.append(current_date)
                current_date += timedelta(days=1)
            
            total_dates = len(date_list)
            logger.info(f"ğŸ“Š ë°±í•„í•  ë‚ ì§œ ìˆ˜: {total_dates}ê°œ (í‰ì¼ë§Œ)")
            
            if total_dates == 0:
                logger.info("âœ… ì²˜ë¦¬í•  ë‚ ì§œê°€ ì—†ìŠµë‹ˆë‹¤.")
                return True
            
            successful_dates = []
            failed_dates = []
            
            # ê° ë‚ ì§œë³„ë¡œ Bronze Layer ì²˜ë¦¬
            for i, target_date in enumerate(date_list, 1):
                logger.info(f"\n{'='*60}")
                logger.info(f"ğŸ“… Bronze Layer {i}/{total_dates} ì²˜ë¦¬ ì¤‘: {target_date}")
                logger.info(f"{'='*60}")
                
                try:
                    # Bronze Layer ì „ì²´ ìˆ˜ì§‘ (ê°€ê²© + ë°°ë‹¹)
                    success = self.run_full_collection(target_date, batch_size)
                    
                    if success:
                        successful_dates.append(target_date)
                        logger.info(f"âœ… {target_date} Bronze Layer ì²˜ë¦¬ ì™„ë£Œ")
                    else:
                        failed_dates.append((target_date, "Bronze Layer ìˆ˜ì§‘ ì‹¤íŒ¨"))
                        logger.error(f"âŒ {target_date} Bronze Layer ì²˜ë¦¬ ì‹¤íŒ¨")
                        
                except Exception as e:
                    failed_dates.append((target_date, str(e)))
                    logger.error(f"âŒ {target_date} Bronze Layer ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    continue
            
            # Bronze Layer ë°±í•„ ê²°ê³¼ ìš”ì•½
            logger.info("\n" + "=" * 80)
            logger.info("ğŸ“ˆ Bronze Layer ë°±í•„ ê²°ê³¼ ìš”ì•½")
            logger.info("=" * 80)
            logger.info(f" ì „ì²´ ì²˜ë¦¬ ë‚ ì§œ: {total_dates}ê°œ")
            logger.info(f" ì„±ê³µí•œ ë‚ ì§œ: {len(successful_dates)}ê°œ")
            logger.info(f" ì‹¤íŒ¨í•œ ë‚ ì§œ: {len(failed_dates)}ê°œ")
            
            if failed_dates:
                logger.info(f"\nâŒ ì‹¤íŒ¨í•œ ë‚ ì§œ:")
                for date, error in failed_dates:  # [ìˆ˜ì •] ëª¨ë“  ì‹¤íŒ¨ ë¡œê·¸ ì¶œë ¥
                    logger.info(f"   - {date}: {error}")
            
            logger.info("=" * 80)
            return len(failed_dates) == 0
            
        except Exception as e:
            logger.error(f"âŒ Bronze Layer ë°±í•„ ì‹¤íŒ¨: {e}")
            return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Bronze Layer ë°ì´í„° ìˆ˜ì§‘")
    parser.add_argument("--mode", choices=["full", "price", "dividend"], 
                       default="full", help="ìˆ˜ì§‘ ëª¨ë“œ")
    parser.add_argument("--date", type=str, help="ìˆ˜ì§‘ ë‚ ì§œ (YYYY-MM-DD)")
    
    args = parser.parse_args()
    
    # GCS ì„¤ì •
    gcs_bucket = os.getenv("GCS_BUCKET", "your-stock-dashboard-bucket")
    orchestrator = BronzeLayerOrchestrator(gcs_bucket=gcs_bucket)
    
    # ë‚ ì§œ íŒŒì‹±
    target_date = None
    if args.date:
        target_date = datetime.strptime(args.date, "%Y-%m-%d").date()
    
    try:
        if args.mode == "full":
            orchestrator.run_full_collection(target_date)
        elif args.mode == "price":
            orchestrator.run_price_only_collection(target_date)
        elif args.mode == "dividend":
            orchestrator.run_dividend_only_collection(target_date)
            
    except Exception as e:
        logger.error(f"âŒ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        raise

if __name__ == "__main__":
    main()
