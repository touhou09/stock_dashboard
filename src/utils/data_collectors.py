"""
Bronze Layer ë°ì´í„° ìˆ˜ì§‘ ëª¨ë“ˆ
- Wikipediaì—ì„œ S&P 500 ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ìˆ˜ì§‘
- yfinance APIë¥¼ í†µí•œ ê°€ê²© ë° ë°°ë‹¹ ë°ì´í„° ìˆ˜ì§‘
"""

import yfinance as yf
import pandas as pd
from datetime import datetime, timedelta, timezone
import time
import random
import requests
from io import StringIO
from typing import List, Tuple
import logging

logger = logging.getLogger(__name__)

class SP500Collector:
    """S&P 500 ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ìˆ˜ì§‘ê¸°"""
    
    WIKI_URL = "https://en.wikipedia.org/wiki/List_of_S%26P_500_companies"
    
    def __init__(self):
        self.headers_pool = [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15",
            "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Firefox/121.0",
        ]
    
    def to_yahoo_symbol(self, sym: str) -> str:
        """í´ë˜ìŠ¤ ì£¼ì‹ í‘œê¸°: BRK.B -> BRK-B"""
        return sym.strip().upper().replace(".", "-")
    
    def get_sp500_from_wikipedia(self, max_retries: int = 3, timeout: int = 15) -> pd.DataFrame:
        """Wikipediaì—ì„œ S&P500 êµ¬ì„±ì¢…ëª© í…Œì´ë¸” íŒŒì‹±"""
        last_err = None

        for i in range(max_retries):
            try:
                logger.info(f"Wikipedia ì ‘ê·¼ ì‹œë„ {i+1}/{max_retries}...")
                headers = {
                    "User-Agent": random.choice(self.headers_pool),
                    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
                    "Accept-Language": "en-US,en;q=0.7",
                    "Cache-Control": "no-cache",
                    "Pragma": "no-cache",
                }
                resp = requests.get(self.WIKI_URL, headers=headers, timeout=timeout)
                resp.raise_for_status()
                
                tables = pd.read_html(StringIO(resp.text))
                spx = tables[0]
                
                if "Symbol" not in spx.columns:
                    candidates = [c for c in spx.columns if "symbol" in c.lower() or "ticker" in c.lower()]
                    if candidates:
                        spx = spx.rename(columns={candidates[0]: "Symbol"})
                    else:
                        raise ValueError("Symbol ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                
                logger.info(f"âœ… Wikipediaì—ì„œ S&P 500 ë°ì´í„° ìˆ˜ì§‘ ì„±ê³µ: {len(spx)}ê°œ ì¢…ëª©")
                return spx
                
            except Exception as e:
                last_err = e
                logger.error(f"âŒ Wikipedia ì ‘ê·¼ ì‹¤íŒ¨ (ì‹œë„ {i+1}): {e}")
                if i < max_retries - 1:
                    wait_time = 1.5 * (i + 1)
                    logger.info(f"â³ {wait_time}ì´ˆ í›„ ì¬ì‹œë„...")
                    time.sleep(wait_time)
        
        raise RuntimeError(f"Wikipedia íŒŒì‹± ìµœì¢… ì‹¤íŒ¨: {last_err}")
    
    def normalize_symbols(self, df: pd.DataFrame) -> pd.DataFrame:
        """Yahoo í˜•ì‹ìœ¼ë¡œ ì‹¬ë³¼ ì •ê·œí™”"""
        df = df.copy()
        df["Symbol"] = df["Symbol"].astype(str).map(self.to_yahoo_symbol)
        return df

class PriceDataCollector:
    """ê°€ê²© ë°ì´í„° ìˆ˜ì§‘ê¸°"""
    
    def get_daily_data_for_tickers(self, tickers: List[str], target_date: datetime.date) -> Tuple[List[pd.DataFrame], List[str], List[str]]:
        """ì „ì²´ S&P 500ì˜ í•˜ë£¨ì¹˜ ë°ì´í„°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
        logger.info(f"ğŸ“Š {target_date} í•˜ë£¨ì¹˜ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
        logger.info(f"ğŸ“Š ì „ì²´ ì¢…ëª© ìˆ˜: {len(tickers)}ê°œ")
        
        all_daily_data = []
        successful_tickers = []
        failed_tickers = []
        
        for i, ticker in enumerate(tickers):
            logger.info(f"  ì²˜ë¦¬ ì¤‘: {ticker} ({i+1}/{len(tickers)})")
            
            try:
                stock = yf.Ticker(ticker)
                
                # í•˜ë£¨ì¹˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                start_date = target_date
                end_date = target_date + timedelta(days=1)
                
                hist = stock.history(start=start_date, end=end_date)
                
                if not hist.empty and hist['Close'].notna().any():
                    # ë°ì´í„° ì²˜ë¦¬ - Bronze ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ì •ê·œí™”
                    hist['ticker'] = ticker
                    hist['date'] = hist.index.date  # ë‚ ì§œë§Œ ì¶”ì¶œ
                    hist = hist.reset_index(drop=True)
                    
                    # ì»¬ëŸ¼ëª… ì •ê·œí™” (Bronze ìŠ¤í‚¤ë§ˆ)
                    hist = hist.rename(columns={
                        'Open': 'open',
                        'High': 'high', 
                        'Low': 'low',
                        'Close': 'close',
                        'Volume': 'volume',
                        'Adj Close': 'adj_close'
                    })
                    
                    # ingest_at íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
                    hist['ingest_at'] = datetime.now(timezone.utc)
                    
                    all_daily_data.append(hist)
                    successful_tickers.append(ticker)
                    
                    logger.info(f"    âœ… {ticker}: ${hist['close'].iloc[-1]:.2f}")
                else:
                    failed_tickers.append(ticker)
                    logger.info(f"    âŒ {ticker}: ë°ì´í„° ì—†ìŒ")
                    
            except Exception as e:
                failed_tickers.append(ticker)
                logger.error(f"    âŒ {ticker}: {e}")
            
            # API ì œí•œ ê³ ë ¤í•œ ë”œë ˆì´
            time.sleep(0.5)
            
            # ì§„í–‰ ìƒí™© í‘œì‹œ (50ê°œë§ˆë‹¤)
            if (i + 1) % 50 == 0:
                logger.info(f"    ğŸ“Š ì§„í–‰ë¥ : {i+1}/{len(tickers)} ({((i+1)/len(tickers)*100):.1f}%)")
                logger.info(f"    âœ… ì„±ê³µ: {len(successful_tickers)}ê°œ, âŒ ì‹¤íŒ¨: {len(failed_tickers)}ê°œ")
        
        logger.info(f"\nğŸ“ˆ ìµœì¢… ìˆ˜ì§‘ ê²°ê³¼:")
        logger.info(f"  âœ… ì„±ê³µ: {len(successful_tickers)}ê°œ")
        logger.info(f"  âŒ ì‹¤íŒ¨: {len(failed_tickers)}ê°œ")
        logger.info(f"  ë°ì´í„° í¬ì¸íŠ¸: {sum(len(df) for df in all_daily_data)}ê°œ")
        
        return all_daily_data, successful_tickers, failed_tickers

class DividendDataCollector:
    """ë°°ë‹¹ ë°ì´í„° ìˆ˜ì§‘ê¸°"""
    
    def fetch_dividend_events_for_tickers(self, tickers: List[str], since: datetime.date, until: datetime.date) -> pd.DataFrame:
        """
        [Bronze] yfinance ë°°ë‹¹ ì´ë²¤íŠ¸ë¥¼ ì›ì²œ ê·¸ëŒ€ë¡œ ì ì¬ìš© DFë¡œ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
        ì…ë ¥: tickers, since(í¬í•¨), until(í¬í•¨)
        ì¶œë ¥: columns = [ex_date, ticker, amount, ingest_at]
        """
        logger.info(f"\nğŸ’° ë°°ë‹¹ ì´ë²¤íŠ¸ ìˆ˜ì§‘ ì¤‘... ({since} ~ {until})")
        logger.info(f"ğŸ’° ì²˜ë¦¬í•  ì¢…ëª© ìˆ˜: {len(tickers)}ê°œ")
        
        rows = []
        processed_count = 0
        
        for i, ticker in enumerate(tickers, 1):
            if i % 50 == 0 or i == 1:
                logger.info(f"  ğŸ“Š ì§„í–‰ë¥ : {i}/{len(tickers)} ({((i)/len(tickers)*100):.1f}%)")
            
            try:
                tk = yf.Ticker(ticker)
                divs = tk.dividends  # Series(index=ex-date, value=amount)
                
                if divs is None or divs.empty:
                    continue

                s = divs.copy()
                # ì¸ë±ìŠ¤ tz ì •ê·œí™”
                if hasattr(s.index, "tz"):
                    s.index = s.index.tz_convert("UTC").tz_localize(None)

                # ê¸°ê°„ í•„í„°
                mask = (s.index.date >= since) & (s.index.date <= until)
                s = s[mask]
                if s.empty:
                    continue

                for idx, amt in s.items():
                    rows.append({
                        "ex_date": idx.date(),
                        "ticker": ticker,
                        "amount": float(amt),
                        "ingest_at": datetime.now(timezone.utc)
                    })
                    
            except Exception as e:
                logger.error(f"    âŒ {ticker}: {e}")
                continue
            
            # API ì œí•œ ê³ ë ¤
            time.sleep(0.3)
            processed_count += 1
        
        df = pd.DataFrame(rows)
        if not df.empty:
            df = df.sort_values(["ex_date", "ticker"]).reset_index(drop=True)
            logger.info(f"âœ… ë°°ë‹¹ ì´ë²¤íŠ¸ ìˆ˜ì§‘ ì™„ë£Œ: {len(df)}ê°œ ì´ë²¤íŠ¸")
        else:
            logger.info("âœ… ë°°ë‹¹ ì´ë²¤íŠ¸ ìˆ˜ì§‘ ì™„ë£Œ: 0ê°œ ì´ë²¤íŠ¸")
            
        return df
